{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tWzt_ckQEAFH"
   },
   "source": [
    "# Estadística Bayesiana\n",
    "\n",
    "> *Wikipedia*: \n",
    "\n",
    "> Bayesian statistics is a theory in the field of statistics based on the **Bayesian interpretation of probability** where probability expresses a degree of belief in an event. \n",
    "\n",
    "> The degree of belief may be based on prior knowledge about the event, such as the results of previous experiments, or on personal beliefs about the event. \n",
    "\n",
    "> This differs from a number of other interpretations of probability, such as the frequentist interpretation that views probability as the limit of the relative frequency of an event after many trials. \n",
    "\n",
    "## Fórmula de Bayes\n",
    "\n",
    "El teorema de Bayes es un teorema fundamental en la estadística bayesiana. \n",
    "\n",
    "$$ P(H | E) = \\frac{P(E | H)P(H)}{P(E)}$$\n",
    "\n",
    "La fórmula de Bayes se puede utilizar en estadísticas frecuentistas para calcular **probabilidades condicionales**, pero en la estadística bayesiana se utiliza para calcular **probabilidades posteriores** (en contraposición a **probabilidades previas (a priori)**), dadas las observaciones.\n",
    "\n",
    "> Por ejemplo, se observa que un paciente tiene cierto síntoma ($E$), y la fórmula de Bayes se puede usar para calcular la probabilidad de que un diagnóstico ($H$) sea correcto, dada esa observación.\n",
    "\n",
    "La estadística bayesiana **interpreta las probabilidades como medidas de credibilidad** (qué tan seguros estamos) en un evento, y **no como la frecuencia de eventos a largo plazo**.\n",
    "\n",
    "Las creencias se aplican a los individuos, no a la naturaleza, por lo que hay lugar para creencias conflictivas entre los individuos. Las diferentes creencias no se interpretan como errores, sino como **diferentes estados de conocimiento sobre un evento**.\n",
    "\n",
    "La fórmula se interpreta como una **actualización de la creencia después de observar los datos**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XQEQlBUREAFL"
   },
   "source": [
    "# Bayesian Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LM0LjzoIEAFL"
   },
   "source": [
    "### Probabilidades: bayesianismo\n",
    "\n",
    "Imaginemos ahora el siguiente escenario. Queremos saber la *probabilidad* de conseguir el Oscar por la última película que ha protagonizado un actor.\n",
    "\n",
    "En este caso, la noción *frecuentista* de  una **serie de juicios** no está bien definida: cada año la situación es diferente, no hay series de juicios idénticos a considerar. Podemos concluir que la noción clásica de probabilidad no se aplica a estas situaciones.\n",
    "\n",
    "Pero el **bayesianismo** define la probabilidad de una manera diferente: **el grado de creencia de que ocurrirá un evento**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0BF5Mz81EAFM"
   },
   "source": [
    "## La regla de Bayes\n",
    "\n",
    "La principal herramienta del análisis bayesiano es el teorema de Bayes, presentado en 1763:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conocemos que: \n",
    "- P(AB) = P(A|B)P(B)\n",
    "- P(BA) = P(B|A)P(A)\n",
    "- P (BA) = P(AB) \n",
    "\n",
    "    - P(A) => Probabilidad a priori\n",
    "    - P(B) => Probabilidad de salida\n",
    "    - P(B/A)\n",
    "    - P(A/B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bml-o1SoEAFM"
   },
   "source": [
    "<b> Bayes Theorem </b> <br>\n",
    "$$ P(A | B) = \\frac{P(B | A)P(A)}{P(B)}$$\n",
    "</div>   \n",
    "\n",
    "Este teorema describe la relación entre las probabilidades condicionales de dos eventos.\n",
    "\n",
    "Es fácil demostrar que esto es cierto. Es solo aritmética básica basada en reglas de probabilidad (regla de la cadena):\n",
    "\n",
    "+ Sabemos que $ P(A \\mbox{ and } B) = P(A)P(B | A) $.\n",
    "+ Pero también es cierto que $ P(A \\mbox{ and } B) = P(B)P(A | B)$.\n",
    "+ Entonces, $ P(A)P(B | A) = P(B)P(A | B)$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-8m-jqZmEAFM"
   },
   "source": [
    "Aunque esto se llama teorema de Bayes, la **forma general** del mismo, como se establece aquí, en realidad no fue escrita por primera vez por Thomas Bayes, sino por Pierre-Simon Laplace. Lo que hizo Bayes fue derivar el caso especial de esta fórmula para \"invertir\" la distribución binomial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rTMo3RViEAFM"
   },
   "source": [
    "### Hipótesis y evidencias\n",
    "\n",
    "La interpretación más común del Teorema de Bayes se basa en considerar que $ A $ es una hipótesis $H$, y $B$ una nueva evidencia $E$, que debería modificar nuestra creencia en $H$:\n",
    "\n",
    "$$P(H | E) = P(H) \\frac{P(E|H)}{P(E)}$$\n",
    "\n",
    "Esto se denomina **interpretación diacrónica** porque describe cómo *una hipótesis debe actualizarse con el tiempo cada vez que se encuentra una nueva evidencia*.\n",
    "\n",
    "+ $P(H | E)$ es denominada la **posterior**.\n",
    "+ $P(H)$ es denominada la **prior probability** de la hipótesis.\n",
    "+ $P(E | H)$ es denominada la **likelihood** de la evidencia.\n",
    "+ $P(E)$ es una constante normalizadora. Si hay $n$ hipótesis que son **mutuamente excluyentes** y *colectivamente exhaustivas*, podemos calcular $P(E)$ como:\n",
    "\n",
    "$$ P(E) = P(H_1)P(E|H_1) + \\dots + P(H_n)P(E|H_n)$$\n",
    "\n",
    "\n",
    "En general, $P(H | E), P(H), P(E|H), P(E)$ son funciones. Podemos extraer estimaciones puntuales, establecer estimaciones y proposiciones probabilísticas de $P(H | E)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GJXD9SqUEAFM"
   },
   "source": [
    "### Visualización de la regla de Bayes<br>\n",
    "\n",
    "Digamos $P(H_{yes})=5\\%$ es la prevalencia de una enfermedad. \n",
    "\n",
    "A cada individuo se le hace una prueba con precisión $P(E_{yes}|H_{yes})=P(E_{no}|H_{no}) = 90\\%$.  \n",
    "\n",
    "Queremos saber la **probabilidad de tener la enfermedad si dio positivo**:\n",
    "\n",
    "$$Pr(H_{yes}|E_{yes})$$. \n",
    "\n",
    "Podemos usar la regla de Bayes para calcular este valor posterior:\n",
    "\n",
    "$$ P(H_{yes}|E_{yes}) = \\frac{P(H_{yes}) P(E_{yes}|H_{yes}) }{P(E_{yes})} = $$\n",
    "\n",
    "$$ = \\frac{P(H_{yes})P(E_{yes}|H_{yes}) }{P(H_{yes})P(E_{yes}|H_{yes}) + P(H_{no})P(E_{yes}|H_{no})} $$\n",
    "\n",
    "Es decir\n",
    "\n",
    "$$ = \\frac{0.05 \\times 0.9}{0.05 \\times 0.9 + 0.95 \\times 0.1} \\approx 0.32 $$\n",
    "\n",
    "A muchos les resulta contradictorio que esta probabilidad sea mucho menor que $90\\% $; este gif animado puede ayuda a comprender el fenómeno"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8VnmorIULkH4"
   },
   "source": [
    "![ChessUrl](https://raw.githubusercontent.com/simplystats/simplystats.github.io/master/_images/bayes.gif \"chess\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "19bSZkZrEAFN"
   },
   "source": [
    "### Ejemplo: Monty Hall Problem\n",
    "\n",
    "> \"*Let's Make a Deal*\" is a television game show which originated in the United States and has since been produced in many countries throughout the world. The show is based around deals offered to members of the audience by the host. The traders usually have to weigh the possibility of an offer for valuable prizes, or undesirable items, referred to as \"Zonks\". \n",
    "\n",
    ">*Source: Wikipedia*.\n",
    "\n",
    "Monty Hall fue el anfitrión original del juego. El problema de Monty Hall se basa en uno de los juegos habituales del programa. \n",
    "> Suponga que está en el programa de juegos y tiene la opción de elegir entre tres puertas: detrás de una puerta hay un automóvil; detrás de los demás, cabras.\n",
    "> Eliges una puerta, dices la puerta A (la puerta no está abierta) y el anfitrión, que sabe qué hay detrás de las puertas, abre la puerta B, que tiene una cabra.\n",
    "> Luego te dice: \"¿Quieres elegir la Puerta C?\" ¿Le conviene cambiar de elección?\n",
    "> *Source: Wikipedia*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BAoXa7TPEAFO"
   },
   "source": [
    "La mayoría de la gente piensa intuitivamente que no hay diferencia entre quedarse o cambiar, ¡pero esto está mal!\n",
    "\n",
    "La verdad es que si te quedas, la probabilidad de ganar es de 1/3; si cambia sus posibilidades son 2/3.\n",
    "\n",
    "Podemos utilizar el punto de vista bayesiano para resolver este problema. Al principio, hay diferentes hipótesis $H$ con sus correspondientes probabilidades **previas (a priori)**:\n",
    "\n",
    "+ A: el auto está detrás de la puerta A; $P(H=\\mbox{'A'}) = 1/3$\n",
    "+ B: el auto está detrás de la puerta B; $P(H=\\mbox{'B'}) = 1/3$\n",
    "+ C: el auto está detrás de la puerta C; $P(H=\\mbox{'C'}) = 1/3$\n",
    "\n",
    "Eliges A al azar. Si te quedas con A después de que Monty abra la puerta B (esta es nuestra evidencia *E*). Podemos calcular $P(H=\\mbox{'A'}|E)$:\n",
    "\n",
    "$$ P(H=\\mbox{'A'}|E) = \\frac{P(H=\\mbox{'A'})P(E|H=\\mbox{'A'})}{P(E)} $$\n",
    "$$= \\frac{1/3 \\times 1/2}{1/3 \\times 1/2 + 1/3 \\times 0 + 1/3 \\times 1} = 1/3$$ \n",
    "\n",
    "El denominador se puede entender de esta manera: asumimos que inicialmente elegimos A. De ello se deduce que si el automóvil está detrás de A, Monty nos mostrará una cabra detrás de B la mitad del tiempo. Si el auto está detrás de B, Monty nunca nos muestra una cabra detrás de B. Finalmente, si el auto está detrás de C, Monty nos muestra una cabra detrás de B cada vez."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uscZI6LTEAFO"
   },
   "source": [
    "**¿Cuál es la probabilidad si cambiamos?**\n",
    "\n",
    "Para saber $P(H=\\mbox{'C'}|E)$ también puede aplicar el teorema de Bayes directamente, pero hay una forma más sencilla de calcularlo: dado que la probabilidad de que esté detrás de A es 1/3 y la suma de las dos probabilidades debe ser igual a 1, la probabilidad de que el automóvil esté detrás de C es 1−1/3 = 2/3.\n",
    "\n",
    "Samuel Arbesman, Wired, 11.26.14: \n",
    "\n",
    "> De hecho, Paul Erdős, uno de los matemáticos más prolíficos y destacados involucrados en la probabilidad, cuando se le habló inicialmente del problema de Monty Hall también fue víctima de no entender por qué abrir una puerta debería hacer alguna diferencia. Incluso cuando se le dio la explicación matemática varias veces, no estaba realmente convencido. Pasaron varios días antes de que finalmente entendiera la solución correcta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yTpJnBhdEAFO"
   },
   "source": [
    "Hagamos una simulación del juego para calcular $P(H=\\mbox{'C'}|E)$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K9ePwTNPEAFO",
    "outputId": "e2014d4e-cd79-4f3e-f83e-55036d93682f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cambiar tiene 66493 wins y 33507 losses: tu ganas 66.5% del tiempo\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "iterations = 100000\n",
    "doors = [\"goat\"] * 2 + [\"car\"]\n",
    "change_wins = 0\n",
    "change_loses = 0\n",
    "\n",
    "for i in range(iterations):\n",
    "    random.shuffle(doors)\n",
    "    \n",
    "    # escoges la puerta n:\n",
    "    n = random.randrange(3)\n",
    "    \n",
    "    # monty escoge la puerta k, k!= n y puertas [k]!= \"coche\"\n",
    "    sequence = list(range(3))\n",
    "    random.shuffle(sequence)\n",
    "    for k in sequence:\n",
    "        if k == n or doors[k] == \"car\":\n",
    "            continue\n",
    "    \n",
    "    # ahora si cambias, pierdes si puertas [n] == \"car\"\n",
    "    if doors[n] == \"car\":\n",
    "        change_loses += 1\n",
    "    else:\n",
    "        change_wins += 1\n",
    "\n",
    "perc = (100.0 * change_wins) / (change_wins + change_loses)\n",
    "print(\"cambiar tiene %s wins y %s losses: tu ganas %.1f%% del tiempo\" % (change_wins, change_loses, perc))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "include_colab_link": true,
   "name": "11. Bayesian Data Analysis.ipynb",
   "provenance": []
  },
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "nteract": {
   "version": "0.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
